{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tldr prototyping\n",
    "\n",
    "short-term goal:\n",
    "\n",
    "* focus on tools to generate input functions for tensorflow Estimator API for different categories of problem\n",
    "\n",
    "seems like there are 3 generic steps before you get to the tensorflow part:\n",
    "\n",
    "  1. **loading** the data. depends on how data is saved (e.g. a CSV, folder of text files, etc) but not language or model directly\n",
    "  2. **preprocessing** the text. tokenizing, stemming, stopwords, etc. depends on language and application, and (to a lesser extent) the model. but not on how the files were saved.\n",
    "  3. **encoding** the data to send to tensorflow. whatever process maps tokens to a bag of words, sequence of one-hot encoded vectors, etc. depends on the model structure more than anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1230"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load our sample data\n",
    "textfile = \"winereviews.txt\"\n",
    "rawtext = [x.decode(\"ascii\", errors=\"ignore\") for x in open(textfile, \"rb\").readlines() if len(x) > 5]\n",
    "len(rawtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lovely delicate, fragrant Rhone wine. Polished leather and strawberries. Perhaps a bit dilute, but good for drinking now. ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rawtext[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_rating(x):\n",
    "    x = x.lower().strip()\n",
    "    if \"no stars\" in x.lower():\n",
    "        return 0, x.replace(\"no stars\", \"\")\n",
    "    r = re.findall(\"\\*+\", x)\n",
    "    if len(r) > 0:\n",
    "        return len(r[0]), x.replace(\"*\", \"\")\n",
    "    else:\n",
    "        return np.nan, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extracted = [extract_rating(r) for r in rawtext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = [x[1] for x in extracted if not np.isnan(x[0])]\n",
    "ratings = [x[0] for x in extracted if not np.isnan(x[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>lovely delicate, fragrant rhone wine. polished...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>liquorice, cherry fruit. simple and coarse at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thin and completely uninspiring.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>big, fat, textured chardonnay - nuts and butte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                               text\n",
       "0       3  lovely delicate, fragrant rhone wine. polished...\n",
       "1       2  liquorice, cherry fruit. simple and coarse at ...\n",
       "2       1                  thin and completely uninspiring. \n",
       "3       0                                            rough. \n",
       "4       3  big, fat, textured chardonnay - nuts and butte..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"text\":text, \"rating\":ratings})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"wineratings.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [nltk.word_tokenize(x) for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lovely delicate, fragrant rhone wine. polished leather and strawberries. perhaps a bit dilute, but good for drinking now. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lovely',\n",
       " 'delicate',\n",
       " ',',\n",
       " 'fragrant',\n",
       " 'rhone',\n",
       " 'wine',\n",
       " '.',\n",
       " 'polished',\n",
       " 'leather',\n",
       " 'and',\n",
       " 'strawberries',\n",
       " '.',\n",
       " 'perhaps',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'dilute',\n",
       " ',',\n",
       " 'but',\n",
       " 'good',\n",
       " 'for',\n",
       " 'drinking',\n",
       " 'now',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2757\n"
     ]
    }
   ],
   "source": [
    "wordlist = list(set([token for doc in tokens for token in doc]))\n",
    "word_index = {wordlist[i]:i for i in range(len(wordlist))}\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"dilute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_to_array(doc, wi):\n",
    "    arr = np.zeros(len(wi))\n",
    "    for token in doc:\n",
    "        arr[wi[token]] += 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_array(tokens[0], word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_tokenizer(x):\n",
    "    \"\"\"\n",
    "    Nothing fancy here.\n",
    "    \"\"\"\n",
    "    x = x.lower().strip()\n",
    "    for c in string.digits+string.punctuation:\n",
    "        x = x.replace(c, \" \")\n",
    "    return x.split()\n",
    "    \n",
    "class Prepper(object):\n",
    "    \"\"\"\n",
    "    Boring prototype class for step 2\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, corpus, tokenizer=generic_tokenizer):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.tokenize = tokenizer\n",
    "        self.token_list = self._make_tokenlist(corpus)\n",
    "        self.token_index = self._make_index(self.token_list)\n",
    "        self._numtokens = len(self.token_index)\n",
    "\n",
    "        \n",
    "    def _make_tokenlist(self, corpus, minlen=2):\n",
    "        \"\"\"\n",
    "        Input a list of strings representing the documents in the\n",
    "        corpus; return a list of all the distinct words in the corpus\n",
    "        \"\"\"\n",
    "        return list(set([token for doc in corpus \n",
    "                         for token in self.tokenize(doc)\n",
    "                        if len(token) >= minlen]))\n",
    "    \n",
    "    def _make_index(self, tokenlist):\n",
    "        \"\"\"\n",
    "        invert the token list to get a dictionary, where each\n",
    "        key is a token and each value is the token's index\n",
    "        \"\"\"\n",
    "        return {tokenlist[i]:i for i in range(len(tokenlist))}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._numtokens\n",
    "    \n",
    "    def __call__(self, tokens):\n",
    "        \"\"\"\n",
    "        Input a list of tokens, return a list of indices\n",
    "        \"\"\"\n",
    "        return [self.token_index[t] for t in tokens if t in self.token_index]\n",
    "    \n",
    "    def __getitem__(self, indices):\n",
    "        \"\"\"\n",
    "        Input a list of indices, return the associated tokens\n",
    "        \"\"\"\n",
    "        return [self.token_list[i] for i in indices if i < self._numtokens]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lovely delicate, fragrant rhone wine. polished leather and strawberries. perhaps a bit dilute, but good for drinking now. '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2579"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = Prepper(text)\n",
    "len(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lovely delicate, fragrant rhone wine. polished leather and strawberries. perhaps a bit dilute, but good for drinking now. '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1908, 2282, 1534, 831, 386, 1396, 1661, 1563, 946, 718, 485, 1474]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = prep(text[0].split())\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lovely',\n",
       " 'fragrant',\n",
       " 'rhone',\n",
       " 'polished',\n",
       " 'leather',\n",
       " 'and',\n",
       " 'perhaps',\n",
       " 'bit',\n",
       " 'but',\n",
       " 'good',\n",
       " 'for',\n",
       " 'drinking']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def densify(x, N):\n",
    "    \"\"\"\n",
    "    input a list of token indices and a vector length; return a dense array\n",
    "    \"\"\"\n",
    "    dense = np.zeros(N, dtype=int)\n",
    "    dense[np.array(x)] = 1\n",
    "    return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densify(ind, len(prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.estimator.inputs.numpy_input_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.arange(4) * 1.0\n",
    "height = np.arange(32, 36)\n",
    "x = {'age': age, 'height': height}\n",
    "y = np.arange(-32, -28)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    for i in range(10):\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "          x, y, batch_size=2, shuffle=False, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
