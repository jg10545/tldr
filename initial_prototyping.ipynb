{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tldr prototyping\n",
    "\n",
    "short-term goal:\n",
    "\n",
    "* focus on tools to generate input functions for tensorflow Estimator API for different categories of problem\n",
    "\n",
    "seems like there are 3 generic steps before you get to the tensorflow part:\n",
    "\n",
    "  1. **loading** the data. depends on how data is saved (e.g. a CSV, folder of text files, etc) but not language or model directly\n",
    "  2. **preprocessing** the text. tokenizing, stemming, stopwords, etc. depends on language and application, and (to a lesser extent) the model. but not on how the files were saved.\n",
    "  3. **encoding** the data to send to tensorflow. whatever process maps tokens to a bag of words, sequence of one-hot encoded vectors, etc. depends on the model structure more than anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1230"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load our sample data\n",
    "textfile = \"winereviews.txt\"\n",
    "rawtext = [x.decode(\"ascii\", errors=\"ignore\") for x in open(textfile, \"rb\").readlines() if len(x) > 5]\n",
    "len(rawtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/joe/projects/tldr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lovely delicate, fragrant Rhone wine. Polished leather and strawberries. Perhaps a bit dilute, but good for drinking now. ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rawtext[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_rating(x):\n",
    "    x = x.lower().strip()\n",
    "    if \"no stars\" in x.lower():\n",
    "        return 0, x.replace(\"no stars\", \"\")\n",
    "    r = re.findall(\"\\*+\", x)\n",
    "    if len(r) > 0:\n",
    "        return len(r[0]), x.replace(\"*\", \"\")\n",
    "    else:\n",
    "        return np.nan, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extracted = [extract_rating(r) for r in rawtext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = [x[1] for x in extracted if not np.isnan(x[0])]\n",
    "ratings = [x[0] for x in extracted if not np.isnan(x[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({\"text\":text, \"rating\":ratings})\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv(\"wineratings.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import tldr.prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2579"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagger = tldr.prepare.Bagginator(text)\n",
    "len(bagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lovely delicate, fragrant rhone wine. polished leather and strawberries. perhaps a bit dilute, but good for drinking now. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[462,\n",
       " 1272,\n",
       " 2277,\n",
       " 199,\n",
       " 1788,\n",
       " 759,\n",
       " 378,\n",
       " 2006,\n",
       " 1671,\n",
       " 703,\n",
       " 767,\n",
       " 1553,\n",
       " 2241,\n",
       " 381,\n",
       " 50,\n",
       " 1761,\n",
       " 208]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = bagger(text[0])\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lovely',\n",
       " 'delicate',\n",
       " 'fragrant',\n",
       " 'rhone',\n",
       " 'wine',\n",
       " 'polished',\n",
       " 'leather',\n",
       " 'and',\n",
       " 'strawberries',\n",
       " 'perhaps',\n",
       " 'bit',\n",
       " 'dilute',\n",
       " 'but',\n",
       " 'good',\n",
       " 'for',\n",
       " 'drinking',\n",
       " 'now']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagger[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rave',\n",
       " 'vegetal',\n",
       " 'firmly',\n",
       " 'fine',\n",
       " 'engaging',\n",
       " 'mouvedre',\n",
       " 'exhhuasted',\n",
       " 'finer',\n",
       " 'struck',\n",
       " 'others']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagger.token_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(0.7*len(text))\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [bagger(t) for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_train, features = tldr.encode.encode_dense_bag_of_words(\n",
    "    corpus[:split], ratings[:split],\n",
    "    len(bagger), shuffle=True, num_epochs=100\n",
    "    )\n",
    "\n",
    "input_test, _ = tldr.encode.encode_dense_bag_of_words(\n",
    "    corpus[split:], ratings[split:],\n",
    "    len(bagger), shuffle=False, num_epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9oev5zig\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_summary_steps': 100, '_model_dir': '/tmp/tmp9oev5zig', '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_save_checkpoints_secs': 600}\n"
     ]
    }
   ],
   "source": [
    "logit_model = tf.estimator.LinearClassifier(features, n_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp9oev5zig/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 249.077\n",
      "INFO:tensorflow:global_step/sec: 134.718\n",
      "INFO:tensorflow:step = 101, loss = 12.5402 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.7\n",
      "INFO:tensorflow:step = 201, loss = 7.48252 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.385\n",
      "INFO:tensorflow:step = 301, loss = 4.28763 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.614\n",
      "INFO:tensorflow:step = 401, loss = 3.02067 (0.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.636\n",
      "INFO:tensorflow:step = 501, loss = 3.1227 (0.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.79\n",
      "INFO:tensorflow:step = 601, loss = 2.13723 (0.765 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 630 into /tmp/tmp9oev5zig/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.19451.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f6ed3d6ccc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.train(input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-04-04:49:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9oev5zig/model.ckpt-630\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-04-04:49:07\n",
      "INFO:tensorflow:Saving dict for global step 630: accuracy = 0.471098, average_loss = 1.85989, global_step = 630, loss = 214.507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.47109827,\n",
       " 'average_loss': 1.8598853,\n",
       " 'global_step': 630,\n",
       " 'loss': 214.50677}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.evaluate(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9fqle53k\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_summary_steps': 100, '_model_dir': '/tmp/tmp9fqle53k', '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_save_checkpoints_secs': 600}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNClassifier([100, 100], features, n_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp9fqle53k/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 250.867\n",
      "INFO:tensorflow:global_step/sec: 54.069\n",
      "INFO:tensorflow:step = 101, loss = 0.177203 (1.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0672\n",
      "INFO:tensorflow:step = 201, loss = 0.124044 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.864\n",
      "INFO:tensorflow:step = 301, loss = 0.0413845 (1.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3127\n",
      "INFO:tensorflow:step = 401, loss = 0.0268679 (1.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2824\n",
      "INFO:tensorflow:step = 501, loss = 0.0171006 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7968\n",
      "INFO:tensorflow:step = 601, loss = 0.0173371 (1.240 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 630 into /tmp/tmp9fqle53k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00931517.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f6ed3d10748>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-04-04:53:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9fqle53k/model.ckpt-630\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-04-04:53:26\n",
      "INFO:tensorflow:Saving dict for global step 630: accuracy = 0.485549, average_loss = 2.66293, global_step = 630, loss = 307.124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.48554912,\n",
       " 'average_loss': 2.662926,\n",
       " 'global_step': 630,\n",
       " 'loss': 307.12411}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
