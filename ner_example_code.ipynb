{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data downloaded from\n",
    "\n",
    "https://github.com/Franck-Dernoncourt/NeuroNER/tree/master/data/conll2003/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3283420"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfile = \"/Users/joe/Documents/tldr/data/conll2003_train.txt\"\n",
    "trainraw = open(trainfile, \"r\").read()\n",
    "len(trainraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14986"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [d for d in trainraw.split(\"\\n\\n\")[1:] if len(d) > 1]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter NNP B-NP B-PER\n",
      "Blackburn NNP I-NP I-PER\n"
     ]
    }
   ],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_fn = tldr.load.conll_input_fn(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'chars': <tf.Tensor 'IteratorGetNext:0' shape=(?, 50, 15, 1) dtype=string>,\n",
       "  'num_tokens': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>,\n",
       "  'tokens': <tf.Tensor 'IteratorGetNext:2' shape=(?, 50, 1) dtype=string>},\n",
       " <tf.Tensor 'IteratorGetNext:3' shape=(?, 50) dtype=int32>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_list = list(set(trainraw))\n",
    "len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, word_embeds = tldr.load.embedding_loader(\"data/glove.6B/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'logs/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c3c5063c8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tldr.models.SequenceClassifier(\"logs/\", word_list, word_embeds, char_list, num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 1186.1355, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.83415\n",
      "INFO:tensorflow:loss = 107.36476, step = 101 (35.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1364\n",
      "INFO:tensorflow:loss = 38.956604, step = 201 (31.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74499\n",
      "INFO:tensorflow:loss = 120.86972, step = 301 (36.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10261\n",
      "INFO:tensorflow:loss = 22.25351, step = 401 (32.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.26373\n",
      "INFO:tensorflow:loss = 5.863098, step = 501 (30.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.27869\n",
      "INFO:tensorflow:loss = 15.98761, step = 601 (30.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.13028\n",
      "INFO:tensorflow:loss = 10.084503, step = 701 (31.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20526\n",
      "INFO:tensorflow:loss = 63.679993, step = 801 (31.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.26777\n",
      "INFO:tensorflow:loss = 5.37912, step = 901 (30.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.26998\n",
      "INFO:tensorflow:loss = 18.433472, step = 1001 (30.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.25339\n",
      "INFO:tensorflow:loss = 28.504425, step = 1101 (30.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.25462\n",
      "INFO:tensorflow:loss = 25.790833, step = 1201 (30.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.2372\n",
      "INFO:tensorflow:loss = 14.672546, step = 1301 (30.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.26398\n",
      "INFO:tensorflow:loss = 15.148499, step = 1401 (30.638 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1499 into logs/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.3514404.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c3354e2e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(inpt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-04:00:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-1499\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-04:03:07\n",
      "INFO:tensorflow:Saving dict for global step 1499: accuracy = 0.0001334579, global_step = 1499, loss = 1797.9877\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1499: logs/model.ckpt-1499\n"
     ]
    }
   ],
   "source": [
    "eval = model.evaluate(inpt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.0001334579, 'global_step': 1499, 'loss': 1797.9877}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-1499\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ground Control to Major <b><text style=color:green>Tom</text></b>: I <b><text style=color:green>bless</text></b>the rains down in <b><text style=color:yellow>Africa</text></b>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tldr.util.tagprint(model, \"Ground Control to Major Tom: I bless the rains down in Africa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
